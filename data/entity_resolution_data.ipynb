{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Entity Resolution Data \u2192 Neo4j KG\n",
        "\n",
        "This notebook follows the ERKG flow (datasets \u2192 graph): load entity-resolution outputs, build nodes, and add relationships in Neo4j.\n",
        "\n",
        "Update the **Configuration** section with your paths and Neo4j credentials before running."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n",
        "Set the file paths and Neo4j connection info. Defaults mirror the ERKG notebooks (local Neo4j Desktop)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Paths\n",
        "BASE_DIR = Path('.')\n",
        "EXPORT_JSON = Path(os.getenv('ER_EXPORT_JSON', 'data/export.json'))  # Senzing export\n",
        "RAW_DATA_DIR = Path(os.getenv('ER_RAW_DATA_DIR', 'data/raw'))        # optional raw inputs\n",
        "\n",
        "# Neo4j connection (match ERKG notebooks defaults)\n",
        "NEO4J_URI = os.getenv('NEO4J_URI', 'neo4j://localhost:7687')\n",
        "NEO4J_USER = os.getenv('NEO4J_USER', 'neo4j')\n",
        "NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD', 'neo4j')  # change me\n",
        "\n",
        "EXPORT_JSON, RAW_DATA_DIR, NEO4J_URI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Neo4j Helpers\n",
        "Create a small helper to run Cypher from Python (similar pattern to ERKG `graph.ipynb`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from neo4j import GraphDatabase\n",
        "\n",
        "def run_cypher(query, params=None):\n",
        "    params = params or {}\n",
        "    with GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD)) as driver:\n",
        "        with driver.session() as session:\n",
        "            return list(session.run(query, params))\n",
        "\n",
        "# Quick connectivity check\n",
        "run_cypher('RETURN 1 AS ok')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Senzing Export\n",
        "The Senzing export is typically a JSON array or JSONL. This loader handles either. Adjust if your export format differs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def load_export(path: Path):\n",
        "    text = path.read_text(encoding='utf-8')\n",
        "    text_stripped = text.lstrip()\n",
        "    if text_stripped.startswith('['):\n",
        "        return json.loads(text)\n",
        "    # assume JSON Lines\n",
        "    rows = []\n",
        "    for line in text.splitlines():\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "        rows.append(json.loads(line))\n",
        "    return rows\n",
        "\n",
        "entities = load_export(EXPORT_JSON)\n",
        "len(entities)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Normalize Records\n",
        "Convert Senzing entities into node/relationship payloads.\n",
        "This normalization is intentionally flexible: it looks for common Senzing fields like `ENTITY_ID`, `RECORDS`, `FEATURES`, etc.\n",
        "If your export schema differs, adjust the mapping here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def norm_entities(rows):\n",
        "    entity_rows = []\n",
        "    record_rows = []\n",
        "    name_rows = []\n",
        "    addr_rows = []\n",
        "    phone_rows = []\n",
        "\n",
        "    for e in rows:\n",
        "        entity_id = e.get('ENTITY_ID') or e.get('ENTITY_ID_STR') or e.get('entity_id')\n",
        "        if entity_id is None:\n",
        "            continue\n",
        "\n",
        "        entity_rows.append({\n",
        "            'entity_id': str(entity_id),\n",
        "            'resolved': True,\n",
        "            'score': e.get('MATCH_LEVEL') or e.get('match_level')\n",
        "        })\n",
        "\n",
        "        for r in e.get('RECORDS', []) or e.get('records', []):\n",
        "            record_id = r.get('RECORD_ID') or r.get('record_id') or r.get('RECORD_ID_STR')\n",
        "            data_source = r.get('DATA_SOURCE') or r.get('data_source')\n",
        "\n",
        "            record_rows.append({\n",
        "                'record_id': str(record_id),\n",
        "                'data_source': data_source,\n",
        "                'entity_id': str(entity_id),\n",
        "            })\n",
        "\n",
        "            # Common Senzing record features\n",
        "            for f in r.get('FEATURES', []) or r.get('features', []):\n",
        "                ftype = f.get('FEAT_TYPE') or f.get('feat_type')\n",
        "                fvals = f.get('FEAT_VALUES') or f.get('feat_values') or []\n",
        "                if ftype == 'NAME':\n",
        "                    for v in fvals:\n",
        "                        name_rows.append({\n",
        "                            'record_id': str(record_id),\n",
        "                            'name': v.get('NAME_FULL') or v.get('name_full') or v.get('name')\n",
        "                        })\n",
        "                elif ftype == 'ADDRESS':\n",
        "                    for v in fvals:\n",
        "                        addr_rows.append({\n",
        "                            'record_id': str(record_id),\n",
        "                            'address': v.get('ADDR_FULL') or v.get('addr_full') or v.get('address')\n",
        "                        })\n",
        "                elif ftype == 'PHONE':\n",
        "                    for v in fvals:\n",
        "                        phone_rows.append({\n",
        "                            'record_id': str(record_id),\n",
        "                            'phone': v.get('PHONE_NUMBER') or v.get('phone_number') or v.get('phone')\n",
        "                        })\n",
        "\n",
        "    return entity_rows, record_rows, name_rows, addr_rows, phone_rows\n",
        "\n",
        "entity_rows, record_rows, name_rows, addr_rows, phone_rows = norm_entities(entities)\n",
        "len(entity_rows), len(record_rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Neo4j Schema\n",
        "Create constraints and indexes for fast merge."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "schema_cypher = [\n",
        "    'CREATE CONSTRAINT entity_id_unique IF NOT EXISTS FOR (e:Entity) REQUIRE e.entity_id IS UNIQUE',\n",
        "    'CREATE CONSTRAINT record_id_unique IF NOT EXISTS FOR (r:Record) REQUIRE r.record_id IS UNIQUE',\n",
        "    'CREATE INDEX name_value IF NOT EXISTS FOR (n:Name) ON (n.value)',\n",
        "    'CREATE INDEX address_value IF NOT EXISTS FOR (a:Address) ON (a.value)',\n",
        "    'CREATE INDEX phone_value IF NOT EXISTS FOR (p:Phone) ON (p.value)',\n",
        "]\n",
        "for stmt in schema_cypher:\n",
        "    run_cypher(stmt)\n",
        "\n",
        "'Schema ready'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Entities and Records\n",
        "Batch insert nodes and relationships. Adjust batch size for your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def chunks(rows, size=1000):\n",
        "    for i in range(0, len(rows), size):\n",
        "        yield rows[i:i+size]\n",
        "\n",
        "entity_cypher = '''\n",
        "UNWIND $rows AS row\n",
        "MERGE (e:Entity {entity_id: row.entity_id})\n",
        "SET e.resolved = row.resolved, e.score = row.score\n",
        "'''\n",
        "\n",
        "record_cypher = '''\n",
        "UNWIND $rows AS row\n",
        "MERGE (r:Record {record_id: row.record_id})\n",
        "SET r.data_source = row.data_source\n",
        "WITH r, row\n",
        "MATCH (e:Entity {entity_id: row.entity_id})\n",
        "MERGE (r)-[:RESOLVED_TO]->(e)\n",
        "'''\n",
        "\n",
        "for batch in chunks(entity_rows, 1000):\n",
        "    run_cypher(entity_cypher, {'rows': batch})\n",
        "\n",
        "for batch in chunks(record_rows, 1000):\n",
        "    run_cypher(record_cypher, {'rows': batch})\n",
        "\n",
        "'Entities and records loaded'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Add Attribute Nodes and Relationships\n",
        "Create `Name`, `Address`, and `Phone` nodes, then connect them to `Record` nodes.\n",
        "If your ERKG process uses different feature types, extend this section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "name_cypher = '''\n",
        "UNWIND $rows AS row\n",
        "WITH row WHERE row.name IS NOT NULL AND row.name <> ''\n",
        "MERGE (n:Name {value: row.name})\n",
        "WITH n, row\n",
        "MATCH (r:Record {record_id: row.record_id})\n",
        "MERGE (r)-[:HAS_NAME]->(n)\n",
        "'''\n",
        "\n",
        "addr_cypher = '''\n",
        "UNWIND $rows AS row\n",
        "WITH row WHERE row.address IS NOT NULL AND row.address <> ''\n",
        "MERGE (a:Address {value: row.address})\n",
        "WITH a, row\n",
        "MATCH (r:Record {record_id: row.record_id})\n",
        "MERGE (r)-[:HAS_ADDRESS]->(a)\n",
        "'''\n",
        "\n",
        "phone_cypher = '''\n",
        "UNWIND $rows AS row\n",
        "WITH row WHERE row.phone IS NOT NULL AND row.phone <> ''\n",
        "MERGE (p:Phone {value: row.phone})\n",
        "WITH p, row\n",
        "MATCH (r:Record {record_id: row.record_id})\n",
        "MERGE (r)-[:HAS_PHONE]->(p)\n",
        "'''\n",
        "\n",
        "for batch in chunks(name_rows, 2000):\n",
        "    run_cypher(name_cypher, {'rows': batch})\n",
        "\n",
        "for batch in chunks(addr_rows, 2000):\n",
        "    run_cypher(addr_cypher, {'rows': batch})\n",
        "\n",
        "for batch in chunks(phone_rows, 2000):\n",
        "    run_cypher(phone_cypher, {'rows': batch})\n",
        "\n",
        "'Attributes linked'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sanity Checks\n",
        "A couple of quick counts to verify the KG is populated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run_cypher('MATCH (e:Entity) RETURN count(e) AS entities')\n",
        "run_cypher('MATCH (r:Record) RETURN count(r) AS records')\n",
        "run_cypher('MATCH (:Record)-[rel:RESOLVED_TO]->(:Entity) RETURN count(rel) AS resolved_edges')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notes\n",
        "- If your Senzing export uses different feature names, adjust `norm_entities()`.\n",
        "- If you want to reproduce the ERKG visualization, follow the analysis steps in `impact.ipynb`."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}