{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ontology Alignment Experiments: Graph Analysis Pipeline\n\nThis notebook demonstrates a complete graph analysis pipeline for ontology alignment:\n1. **Exploratory Data Analysis (EDA)** - Understanding the graph structure\n2. **Weakly Connected Components (WCC)** - Identifying connected subgraphs\n3. **Node Similarity** - Finding similar nodes based on shared properties\n4. **Node Embeddings** - Creating vector representations for similarity analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T15:33:02.375407Z",
     "start_time": "2026-02-13T15:32:55.789352Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install neo4j",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting neo4j\n",
      "  Downloading neo4j-6.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.12/dist-packages (from neo4j) (2025.2)\n",
      "Downloading neo4j-6.1.0-py3-none-any.whl (325 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m325.3/325.3 kB\u001B[0m \u001B[31m10.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: neo4j\n",
      "Successfully installed neo4j-6.1.0\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T15:33:09.918795Z",
     "start_time": "2026-02-13T15:33:09.248692Z"
    }
   },
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from neo4j import GraphDatabase\n",
    "from IPython.display import display, HTML\n",
    "import json\n",
    "\n",
    "# Import EDA analyzer\n",
    "sys.path.append('eda')\n",
    "from neo4j_analyzer import Neo4jPropertyAnalyzer, PerformanceMonitor\n",
    "from neo4j_analyzer.report_generator import ReportGenerator\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'neo4j_analyzer'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipython-input-2717938835.py\u001B[0m in \u001B[0;36m<cell line: 0>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;31m# Import EDA analyzer\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0msys\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'eda'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mneo4j_analyzer\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mNeo4jPropertyAnalyzer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mPerformanceMonitor\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     12\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mneo4j_analyzer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreport_generator\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mReportGenerator\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'neo4j_analyzer'",
      "",
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n\n**Neo4j Connection Settings:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neo4j Connection\n",
    "NEO4J_URI = \"bolt://44.204.34.69\"\n",
    "NEO4J_USER = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"decibels-defenses-president\"\n",
    "\n",
    "# Analysis Settings\n",
    "USE_FAST_MODE = True      # Use Cypher aggregations for large graphs\n",
    "SAMPLE_SIZE = 50000       # Sample size for standard mode\n",
    "FETCH_SIZE = 2000         # Batch size for data extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: Exploratory Data Analysis (EDA)\n\n",
    "Understanding the structure and properties of our graph data before running algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Initialize Analyzer and Explore Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize analyzer\n",
    "analyzer = Neo4jPropertyAnalyzer(\n",
    "    uri=NEO4J_URI,\n",
    "    user=NEO4J_USER,\n",
    "    password=NEO4J_PASSWORD,\n",
    "    fetch_size=FETCH_SIZE\n",
    ")\n",
    "\n",
    "# Get all node labels in the database\n",
    "labels = analyzer.get_node_labels()\n",
    "print(f\"Found {len(labels)} node labels in the database:\")\n",
    "for label in labels:\n",
    "    count = analyzer.get_node_count(label)\n",
    "    print(f\"  - {label}: {count:,} nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Analyze Node Properties\n\n",
    "Analyze properties to understand:\n",
    "- **Categorical properties**: Low cardinality, good for grouping\n",
    "- **Unique properties**: High cardinality, good for identifiers\n",
    "- **Property distributions**: Understanding data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze properties for each label\n",
    "all_results = {}\n",
    "\n",
    "for label in labels:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Analyzing label: {label}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    if USE_FAST_MODE:\n",
    "        summary = analyzer.get_property_summary_fast(label)\n",
    "    else:\n",
    "        summary = analyzer.get_property_summary(label, sample_size=SAMPLE_SIZE)\n",
    "    \n",
    "    all_results[label] = summary\n",
    "    ReportGenerator.print_summary(summary, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Visualize Property Types Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate property types across all labels\n",
    "property_type_counts = {}\n",
    "\n",
    "for label, summary in all_results.items():\n",
    "    for prop_name, prop_info in summary.items():\n",
    "        prop_type = prop_info.get('type', 'UNKNOWN')\n",
    "        if prop_type not in property_type_counts:\n",
    "            property_type_counts[prop_type] = 0\n",
    "        property_type_counts[prop_type] += 1\n",
    "\n",
    "# Create visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Pie chart\n",
    "ax1.pie(property_type_counts.values(), labels=property_type_counts.keys(), \n",
    "        autopct='%1.1f%%', startangle=90)\n",
    "ax1.set_title('Property Types Distribution')\n",
    "\n",
    "# Bar chart\n",
    "ax2.bar(property_type_counts.keys(), property_type_counts.values())\n",
    "ax2.set_xlabel('Property Type')\n",
    "ax2.set_ylabel('Count')\n",
    "ax2.set_title('Property Types Count')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: Weakly Connected Components (WCC)\n\n",
    "**Algorithm**: WCC identifies groups of nodes that are connected to each other, even if the connections are indirect.\n\n",
    "**Key Parameters:**\n",
    "- `GRAPH_NAME`: Name of the GDS graph projection to analyze\n",
    "- `USER_LABEL`: Node label to focus on (e.g., 'Stream')\n",
    "- `PROPERTY_LABEL`: Related property nodes (e.g., 'Property')\n",
    "- `REL_TYPE`: Relationship type connecting nodes (e.g., 'HAS')\n\n",
    "**What it does:**\n",
    "- Finds all connected components in the graph\n",
    "- Assigns a `component_id` to each node\n",
    "- Filters components with size > 1 (groups with multiple nodes)\n",
    "- Writes `component_id_2` property to Stream nodes for downstream analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WCC Configuration\n",
    "GRAPH_NAME = \"node-embedding-graph\"\n",
    "USER_LABEL = \"Stream\"\n",
    "PROPERTY_LABEL = \"Property\"\n",
    "REL_TYPE = \"HAS\"\n",
    "\n",
    "print(f\"Running WCC on graph: {GRAPH_NAME}\")\n",
    "print(f\"Analyzing nodes: {USER_LABEL}\")\n",
    "print(f\"Connected via: {REL_TYPE} -> {PROPERTY_LABEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run WCC Algorithm\n",
    "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "\n",
    "with driver:\n",
    "    with driver.session() as session:\n",
    "        # Run WCC and assign component IDs\n",
    "        result = session.run(\n",
    "            \"CALL gds.wcc.stream($name) \"\n",
    "            \"YIELD nodeId, componentId \"\n",
    "            \"WITH gds.util.asNode(nodeId) AS n, componentId \"\n",
    "            \"WHERE n:Stream \"\n",
    "            \"WITH componentId, collect(n) AS nodes, count(*) AS size \"\n",
    "            \"WHERE size > 1 \"\n",
    "            \"UNWIND nodes AS n \"\n",
    "            \"SET n.component_id_2 = componentId \"\n",
    "            \"RETURN componentId, size \"\n",
    "            \"ORDER BY size DESC, componentId ASC\",\n",
    "            name=GRAPH_NAME,\n",
    "        )\n",
    "        \n",
    "        # Collect results\n",
    "        wcc_results = []\n",
    "        for record in result:\n",
    "            wcc_results.append({\n",
    "                'component_id': record['componentId'],\n",
    "                'size': record['size']\n",
    "            })\n",
    "\n",
    "driver.close()\n",
    "\n",
    "# Display results\n",
    "wcc_df = pd.DataFrame(wcc_results)\n",
    "print(f\"\\nFound {len(wcc_df)} connected components with size > 1\")\n",
    "print(f\"Total nodes in components: {wcc_df['size'].sum():,}\")\n",
    "display(wcc_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Visualize Component Size Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize component sizes\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram of component sizes\n",
    "ax1.hist(wcc_df['size'], bins=50, edgecolor='black')\n",
    "ax1.set_xlabel('Component Size')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Distribution of Component Sizes')\n",
    "ax1.set_yscale('log')\n",
    "\n",
    "# Top 10 largest components\n",
    "top_10 = wcc_df.nlargest(10, 'size')\n",
    "ax2.barh(range(len(top_10)), top_10['size'])\n",
    "ax2.set_yticks(range(len(top_10)))\n",
    "ax2.set_yticklabels([f\"Comp {cid}\" for cid in top_10['component_id']])\n",
    "ax2.set_xlabel('Size')\n",
    "ax2.set_title('Top 10 Largest Components')\n",
    "ax2.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nComponent Statistics:\")\n",
    "print(f\"  Mean size: {wcc_df['size'].mean():.2f}\")\n",
    "print(f\"  Median size: {wcc_df['size'].median():.2f}\")\n",
    "print(f\"  Largest component: {wcc_df['size'].max():,} nodes\")\n",
    "print(f\"  Smallest component: {wcc_df['size'].min():,} nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 3: Node Similarity\n\n",
    "**Algorithm**: Node Similarity finds pairs of nodes that are similar based on their shared neighbors (Jaccard similarity).\n\n",
    "**Key Parameters:**\n",
    "- `GRAPH_NAME`: GDS graph projection (must include component_id_2 property)\n",
    "- `NODE_LABELS`: Filter to specific node types (e.g., ['Stream'])\n",
    "- `similarity > 0`: Only return node pairs with non-zero similarity\n\n",
    "**What it does:**\n",
    "- Compares nodes based on shared properties/neighbors\n",
    "- Calculates Jaccard similarity: |A ∩ B| / |A ∪ B|\n",
    "- Returns pairs of similar nodes with similarity scores\n",
    "- Useful for finding potential duplicates or related entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node Similarity Configuration\n",
    "SIMILARITY_GRAPH_NAME = \"graph-with-component_ids\"\n",
    "NODE_LABELS = [\"Stream\"]\n",
    "\n",
    "print(f\"Running Node Similarity on graph: {SIMILARITY_GRAPH_NAME}\")\n",
    "print(f\"Analyzing node labels: {NODE_LABELS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Node Similarity Algorithm\n",
    "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "\n",
    "with driver:\n",
    "    with driver.session() as session:\n",
    "        result = session.run(\n",
    "            \"CALL gds.nodeSimilarity.stream($name, { \"\n",
    "            \"  nodeLabels: $labels \"\n",
    "            \"}) \"\n",
    "            \"YIELD node1, node2, similarity \"\n",
    "            \"WHERE similarity > 0 \"\n",
    "            \"RETURN gds.util.asNode(node1).id AS node1_id, \"\n",
    "            \"       gds.util.asNode(node1).component_id_2 AS node1_component_id, \"\n",
    "            \"       gds.util.asNode(node2).id AS node2_id, \"\n",
    "            \"       gds.util.asNode(node2).component_id_2 AS node2_component_id, \"\n",
    "            \"       similarity \"\n",
    "            \"ORDER BY similarity DESC \"\n",
    "            \"LIMIT 1000\",  # Limit for notebook display\n",
    "            name=SIMILARITY_GRAPH_NAME,\n",
    "            labels=NODE_LABELS,\n",
    "        )\n",
    "        \n",
    "        # Collect results\n",
    "        similarity_results = []\n",
    "        for record in result:\n",
    "            similarity_results.append({\n",
    "                'node1_id': record['node1_id'],\n",
    "                'node1_component': record['node1_component_id'],\n",
    "                'node2_id': record['node2_id'],\n",
    "                'node2_component': record['node2_component_id'],\n",
    "                'similarity': record['similarity']\n",
    "            })\n",
    "\n",
    "driver.close()\n",
    "\n",
    "# Display results\n",
    "similarity_df = pd.DataFrame(similarity_results)\n",
    "print(f\"\\nFound {len(similarity_df)} similar node pairs (showing top 1000)\")\n",
    "display(similarity_df.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Visualize Similarity Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize similarity scores\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram of similarity scores\n",
    "ax1.hist(similarity_df['similarity'], bins=50, edgecolor='black')\n",
    "ax1.set_xlabel('Similarity Score')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Distribution of Similarity Scores')\n",
    "\n",
    "# Top 20 most similar pairs\n",
    "top_20 = similarity_df.nlargest(20, 'similarity')\n",
    "ax2.barh(range(len(top_20)), top_20['similarity'])\n",
    "ax2.set_yticks(range(len(top_20)))\n",
    "ax2.set_yticklabels([f\"{row['node1_id']}-{row['node2_id']}\" for _, row in top_20.iterrows()], fontsize=8)\n",
    "ax2.set_xlabel('Similarity')\n",
    "ax2.set_title('Top 20 Most Similar Node Pairs')\n",
    "ax2.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nSimilarity Statistics:\")\n",
    "print(f\"  Mean similarity: {similarity_df['similarity'].mean():.4f}\")\n",
    "print(f\"  Median similarity: {similarity_df['similarity'].median():.4f}\")\n",
    "print(f\"  Max similarity: {similarity_df['similarity'].max():.4f}\")\n",
    "print(f\"  Min similarity: {similarity_df['similarity'].min():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 4: Node Embeddings\n\n",
    "**Algorithm**: FastRP (Fast Random Projection) creates vector representations of nodes, followed by KNN (K-Nearest Neighbors) to find similar nodes.\n\n",
    "**Key Parameters:**\n",
    "- `GRAPH_NAME`: GDS graph projection name\n",
    "- `LABELS`: Node labels to include (e.g., ['Stream', 'Game'])\n",
    "- `REL_TYPES`: Relationship types to consider (e.g., ['MODERATOR', 'VIP', 'CHATTER'])\n",
    "- `embeddingDimension`: Size of embedding vectors (128)\n",
    "- `topK`: Number of nearest neighbors to find (10)\n\n",
    "**What it does:**\n",
    "- Creates a graph projection filtered by component_id_2\n",
    "- Generates 128-dimensional embeddings using FastRP\n",
    "- Finds top 10 most similar nodes for each node using KNN\n",
    "- Returns node pairs with similarity scores and component IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node Embeddings Configuration\n",
    "EMBEDDING_GRAPH_NAME = \"graph-with-component_ids\"\n",
    "EMBEDDING_LABELS = [\"Stream\", \"Game\"]\n",
    "EMBEDDING_REL_TYPES = [\"MODERATOR\", \"VIP\", \"CHATTER\"]\n",
    "EMBEDDING_DIMENSION = 128\n",
    "TOP_K = 10\n",
    "\n",
    "print(f\"Running Node Embeddings on graph: {EMBEDDING_GRAPH_NAME}\")\n",
    "print(f\"Node labels: {EMBEDDING_LABELS}\")\n",
    "print(f\"Relationship types: {EMBEDDING_REL_TYPES}\")\n",
    "print(f\"Embedding dimension: {EMBEDDING_DIMENSION}\")\n",
    "print(f\"Top K neighbors: {TOP_K}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run FastRP and KNN\n",
    "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "\n",
    "with driver:\n",
    "    with driver.session() as session:\n",
    "        # Note: This assumes the graph projection and embeddings have been created\n",
    "        # In practice, you would first create the projection and run FastRP\n",
    "        # For this demo, we'll query the KNN results\n",
    "        \n",
    "        result = session.run(\n",
    "            \"CALL gds.knn.stream($name, { \"\n",
    "            \"  nodeProperties: ['embedding'], \"\n",
    "            \"  topK: $topK \"\n",
    "            \"}) \"\n",
    "            \"YIELD node1, node2, similarity \"\n",
    "            \"RETURN gds.util.asNode(node1).id AS node1_id, \"\n",
    "            \"       gds.util.asNode(node1).component_id_2 AS component_id_node_1, \"\n",
    "            \"       gds.util.asNode(node2).id AS node2_id, \"\n",
    "            \"       gds.util.asNode(node2).component_id_2 AS component_id_node_2, \"\n",
    "            \"       similarity \"\n",
    "            \"ORDER BY similarity DESC \"\n",
    "            \"LIMIT 1000\",\n",
    "            name=EMBEDDING_GRAPH_NAME,\n",
    "            topK=TOP_K,\n",
    "        )\n",
    "        \n",
    "        # Collect results\n",
    "        embedding_results = []\n",
    "        for record in result:\n",
    "            embedding_results.append({\n",
    "                'node1_id': record['node1_id'],\n",
    "                'component_id_1': record['component_id_node_1'],\n",
    "                'node2_id': record['node2_id'],\n",
    "                'component_id_2': record['component_id_node_2'],\n",
    "                'similarity': record['similarity']\n",
    "            })\n",
    "\n",
    "driver.close()\n",
    "\n",
    "# Display results\n",
    "embedding_df = pd.DataFrame(embedding_results)\n",
    "print(f\"\\nFound {len(embedding_df)} embedding-based similar pairs (showing top 1000)\")\n",
    "display(embedding_df.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Visualize Embedding-Based Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize embedding similarity scores\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram of embedding similarity scores\n",
    "ax1.hist(embedding_df['similarity'], bins=50, edgecolor='black', alpha=0.7, label='Embeddings')\n",
    "if len(similarity_df) > 0:\n",
    "    ax1.hist(similarity_df['similarity'], bins=50, edgecolor='black', alpha=0.5, label='Node Similarity')\n",
    "ax1.set_xlabel('Similarity Score')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Comparison: Embedding vs Node Similarity')\n",
    "ax1.legend()\n",
    "\n",
    "# Component distribution in embedding results\n",
    "component_counts = embedding_df['component_id_1'].value_counts().head(10)\n",
    "ax2.barh(range(len(component_counts)), component_counts.values)\n",
    "ax2.set_yticks(range(len(component_counts)))\n",
    "ax2.set_yticklabels([f\"Comp {cid}\" for cid in component_counts.index])\n",
    "ax2.set_xlabel('Number of Similar Pairs')\n",
    "ax2.set_title('Top 10 Components by Similar Pairs')\n",
    "ax2.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nEmbedding Similarity Statistics:\")\n",
    "print(f\"  Mean similarity: {embedding_df['similarity'].mean():.4f}\")\n",
    "print(f\"  Median similarity: {embedding_df['similarity'].median():.4f}\")\n",
    "print(f\"  Max similarity: {embedding_df['similarity'].max():.4f}\")\n",
    "print(f\"  Min similarity: {embedding_df['similarity'].min():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary\n\n",
    "This notebook demonstrated a complete graph analysis pipeline:\n\n",
    "1. **EDA**: Explored the graph structure, node labels, and property distributions\n",
    "2. **WCC**: Identified connected components and assigned component_id_2 to nodes\n",
    "3. **Node Similarity**: Found similar nodes based on Jaccard similarity of shared neighbors\n",
    "4. **Node Embeddings**: Created vector representations and found similar nodes using KNN\n\n",
    "## Key Findings:\n",
    "- Component IDs help group related nodes together\n",
    "- Node similarity captures structural similarity based on shared connections\n",
    "- Embeddings capture deeper semantic relationships in the graph\n",
    "- Both approaches complement each other for comprehensive similarity analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
